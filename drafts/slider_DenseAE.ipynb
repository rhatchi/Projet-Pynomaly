{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Machine_Type</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Status</th>\n",
       "      <th>Machine_ID</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>nb_echantillon</th>\n",
       "      <th>freq_echantillonnage</th>\n",
       "      <th>audio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11969</th>\n",
       "      <td>Data/slider/train/normal_id_00_00000692.wav</td>\n",
       "      <td>slider</td>\n",
       "      <td>train</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>692</td>\n",
       "      <td>160000</td>\n",
       "      <td>16000</td>\n",
       "      <td>[-0.01812744 -0.02529907 -0.02410889 ... -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11970</th>\n",
       "      <td>Data/slider/train/normal_id_06_00000093.wav</td>\n",
       "      <td>slider</td>\n",
       "      <td>train</td>\n",
       "      <td>normal</td>\n",
       "      <td>6</td>\n",
       "      <td>93</td>\n",
       "      <td>160000</td>\n",
       "      <td>16000</td>\n",
       "      <td>[ 0.00030518 -0.01733398  0.00076294 ... -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11971</th>\n",
       "      <td>Data/slider/train/normal_id_00_00000686.wav</td>\n",
       "      <td>slider</td>\n",
       "      <td>train</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>686</td>\n",
       "      <td>160000</td>\n",
       "      <td>16000</td>\n",
       "      <td>[ 0.00491333 -0.00527954 -0.01107788 ... -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11972</th>\n",
       "      <td>Data/slider/train/normal_id_06_00000087.wav</td>\n",
       "      <td>slider</td>\n",
       "      <td>train</td>\n",
       "      <td>normal</td>\n",
       "      <td>6</td>\n",
       "      <td>87</td>\n",
       "      <td>160000</td>\n",
       "      <td>16000</td>\n",
       "      <td>[-0.0083313  -0.01031494 -0.01416016 ...  0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11973</th>\n",
       "      <td>Data/slider/train/normal_id_02_00000058.wav</td>\n",
       "      <td>slider</td>\n",
       "      <td>train</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>160000</td>\n",
       "      <td>16000</td>\n",
       "      <td>[0.00817871 0.01330566 0.012146   ... 0.005401...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Path Machine_Type Dataset  \\\n",
       "11969  Data/slider/train/normal_id_00_00000692.wav       slider   train   \n",
       "11970  Data/slider/train/normal_id_06_00000093.wav       slider   train   \n",
       "11971  Data/slider/train/normal_id_00_00000686.wav       slider   train   \n",
       "11972  Data/slider/train/normal_id_06_00000087.wav       slider   train   \n",
       "11973  Data/slider/train/normal_id_02_00000058.wav       slider   train   \n",
       "\n",
       "       Status  Machine_ID  Sample_ID  nb_echantillon  freq_echantillonnage  \\\n",
       "11969  normal           0        692          160000                 16000   \n",
       "11970  normal           6         93          160000                 16000   \n",
       "11971  normal           0        686          160000                 16000   \n",
       "11972  normal           6         87          160000                 16000   \n",
       "11973  normal           2         58          160000                 16000   \n",
       "\n",
       "                                                   audio  \n",
       "11969  [-0.01812744 -0.02529907 -0.02410889 ... -0.01...  \n",
       "11970  [ 0.00030518 -0.01733398  0.00076294 ... -0.01...  \n",
       "11971  [ 0.00491333 -0.00527954 -0.01107788 ... -0.01...  \n",
       "11972  [-0.0083313  -0.01031494 -0.01416016 ...  0.00...  \n",
       "11973  [0.00817871 0.01330566 0.012146   ... 0.005401...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def load_audio(audio_path):\n",
    "    return librosa.load(audio_path, sr=None)\n",
    "\n",
    "df = pd.read_csv('Path_DF.csv')\n",
    "slider_train = df[(df.Dataset == 'train') & (df.Machine_Type == 'slider')]\n",
    "\n",
    "slider_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cette fonction permet de faire une sélection de features MFEC sur un fichier audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_load_stream(wav_name, mono=False):\n",
    "    frameSize = librosa.get_samplerate(wav_name)\n",
    "    hoplength = frameSize // 2\n",
    "    stream = librosa.stream(wav_name, block_length=1, frame_length=frameSize, hop_length=hoplength, mono=mono)\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object stream at 0x7fc4967b2c10>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_load_stream(df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On va créer une fonction qui transforme le fichier MFEC en des vecteurs numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def file_to_vector_array_stream_test_data(file_name, n_mels=128, frames=5, n_fft=1024, hop_length=512, power=1):\n",
    "    \"\"\"\n",
    "    convert file_name to a vector array.\n",
    "    file_name : str\n",
    "        target .wav file\n",
    "    return : numpy.array( numpy.array( float ) )\n",
    "        vector array\n",
    "        * dataset.shape = (dataset_size, feature_vector_length)\n",
    "    \"\"\"\n",
    "    # 01 calculate the number of dimensions\n",
    "    dims = n_mels * frames\n",
    "    \n",
    "    # 02 generate melspectrogram using librosa\n",
    "    stream = file_load_stream(file_name)\n",
    "    sr = librosa.get_samplerate(file_name)\n",
    "    liste = []\n",
    "    for n, y in enumerate(stream):\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, power=power)\n",
    "\n",
    "        # 03 convert melspectrogram\n",
    "\n",
    "        log_mel_spectrogram = 20.0 / power * np.log10(mel_spectrogram + sys.float_info.epsilon)\n",
    "\n",
    "        # 04 calculate total vector size\n",
    "        vector_array_size = len(log_mel_spectrogram[0, :]) - frames + 1  \n",
    "        \n",
    "        # 05 skip too short clips\n",
    "        if vector_array_size < 1:\n",
    "            return np.empty((0, dims))\n",
    "\n",
    "        # 06 generate feature vectors by concatenating multiframes\n",
    "        vector_array = np.zeros((vector_array_size, dims))\n",
    "\n",
    "        for t in range(frames):\n",
    "            vector_array[:, n_mels * t: n_mels * (t + 1)] = log_mel_spectrogram[:, t: t + vector_array_size].T\n",
    "\n",
    "        liste.append(vector_array)\n",
    "\n",
    "    liste = np.asarray(liste)\n",
    "    liste = liste.reshape(liste.shape[0] * liste.shape[1], liste.shape[2])\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532, 640)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_extract = 532\n",
    "\n",
    "file_to_vector_array_stream_test_data(df.iloc[0,0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A partir d'un Dataframe, on crée un ensemble de données exploitable pour le modèle Dense AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réalisé en 195.457 secondes\n"
     ]
    }
   ],
   "source": [
    "def dataset_stream(set_files):\n",
    "    \"\"\"\n",
    "    renvoie une dataset sur laquelle entrainer/évaluer le modèle Dense_AE\n",
    "    set_files est un DataFrame et sa première colonne contient les chemins\n",
    "    \"\"\"\n",
    "    liste = []\n",
    "    for k in range(len(set_files)):\n",
    "        for l in file_to_vector_array_stream_test_data(set_files.iloc[k,0]):\n",
    "            liste.append(l)\n",
    "    return np.asarray(liste)\n",
    "\n",
    "from time import time\n",
    "t0 = time()\n",
    "\n",
    "slider_train_stream = dataset_stream(slider_train)\n",
    "\n",
    "t1 = time() - t0\n",
    "print(\"Réalisé en {} secondes\".format(round(t1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1491728, 640)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slider_train_stream.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On entraine un modèle DenseAE avec la dataset nouvellement créée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Dropout, Flatten, BatchNormalization, ReLU, Reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_denseAE(input_shape = (640,)):\n",
    "    model_dense = Sequential()\n",
    "\n",
    "    # Première couche Encoder\n",
    "    model_dense.add(Dense(512, input_shape = input_shape))\n",
    "    model_dense.add(BatchNormalization())\n",
    "    model_dense.add(ReLU())\n",
    "\n",
    "    # Seconde couche Encoder\n",
    "    model_dense.add(Dense(512))\n",
    "    model_dense.add(BatchNormalization())\n",
    "    model_dense.add(ReLU())\n",
    "\n",
    "    # Troisième couche Encoder\n",
    "    model_dense.add(Dense(512))\n",
    "    model_dense.add(BatchNormalization())\n",
    "    model_dense.add(ReLU())\n",
    "\n",
    "    # Quatrième couche Encoder\n",
    "    model_dense.add(Dense(512))\n",
    "    model_dense.add(BatchNormalization())\n",
    "    model_dense.add(ReLU())\n",
    "\n",
    "    # Couche goulot\n",
    "    model_dense.add(Dense(8))\n",
    "    model_dense.add(BatchNormalization())\n",
    "    model_dense.add(ReLU())\n",
    "\n",
    "    # Première couche Decoder\n",
    "    model_dense.add(Dense(512))\n",
    "    model_dense.add(BatchNormalization())\n",
    "    model_dense.add(ReLU())\n",
    "\n",
    "    # Seconde couche Decoder\n",
    "    model_dense.add(Dense(512))\n",
    "    model_dense.add(BatchNormalization())\n",
    "    model_dense.add(ReLU())\n",
    "\n",
    "    # Troisième couche Decoder\n",
    "    model_dense.add(Dense(512))\n",
    "    model_dense.add(BatchNormalization())\n",
    "    model_dense.add(ReLU())\n",
    "\n",
    "    # Quatrième couche Decoder\n",
    "    model_dense.add(Dense(512))\n",
    "    model_dense.add(BatchNormalization())\n",
    "    model_dense.add(ReLU())\n",
    "\n",
    "    # Couche de reconstruction \n",
    "    model_dense.add(Dense(640))\n",
    "    \n",
    "    return model_dense\n",
    "\n",
    "model_dense = model_denseAE()\n",
    "\n",
    "# On compile \n",
    "model_dense.compile(optimizer='adam', loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/romeo/Formation DataScientist/projet pynomaly'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "filepath = cwd\n",
    "\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2040/2040 [==============================] - 188s 91ms/step - loss: 248.4294 - val_loss: 14.1461\n",
      "INFO:tensorflow:Assets written to: /Users/romeo/Formation DataScientist/projet pynomaly/assets\n",
      "Epoch 2/100\n",
      "2040/2040 [==============================] - 177s 87ms/step - loss: 13.1254 - val_loss: 12.9968\n",
      "INFO:tensorflow:Assets written to: /Users/romeo/Formation DataScientist/projet pynomaly/assets\n",
      "Epoch 3/100\n",
      "2040/2040 [==============================] - 146s 71ms/step - loss: 11.9743 - val_loss: 12.9329\n",
      "INFO:tensorflow:Assets written to: /Users/romeo/Formation DataScientist/projet pynomaly/assets\n",
      "Epoch 4/100\n",
      "2040/2040 [==============================] - 141s 69ms/step - loss: 11.3707 - val_loss: 12.9863\n",
      "Epoch 5/100\n",
      "2040/2040 [==============================] - 146s 71ms/step - loss: 11.0554 - val_loss: 15.2346\n",
      "Epoch 6/100\n",
      "2040/2040 [==============================] - 149s 73ms/step - loss: 10.8746 - val_loss: 11.8894\n",
      "INFO:tensorflow:Assets written to: /Users/romeo/Formation DataScientist/projet pynomaly/assets\n",
      "Epoch 7/100\n",
      "2040/2040 [==============================] - 146s 71ms/step - loss: 10.7452 - val_loss: 12.1330\n",
      "Epoch 8/100\n",
      "2040/2040 [==============================] - 142s 69ms/step - loss: 10.6685 - val_loss: 11.3479\n",
      "INFO:tensorflow:Assets written to: /Users/romeo/Formation DataScientist/projet pynomaly/assets\n",
      "Epoch 9/100\n",
      "2040/2040 [==============================] - 139s 68ms/step - loss: 10.5905 - val_loss: 11.5895\n",
      "Epoch 10/100\n",
      "2040/2040 [==============================] - 147s 72ms/step - loss: 10.5354 - val_loss: 11.4357\n",
      "Epoch 11/100\n",
      "2040/2040 [==============================] - 146s 72ms/step - loss: 10.4999 - val_loss: 11.1108\n",
      "INFO:tensorflow:Assets written to: /Users/romeo/Formation DataScientist/projet pynomaly/assets\n",
      "Epoch 12/100\n",
      "2040/2040 [==============================] - 147s 72ms/step - loss: 10.4489 - val_loss: 11.3485\n",
      "Epoch 13/100\n",
      "2040/2040 [==============================] - 147s 72ms/step - loss: 10.4105 - val_loss: 11.2577\n",
      "Epoch 14/100\n",
      "2040/2040 [==============================] - 144s 70ms/step - loss: 10.3864 - val_loss: 11.7711\n",
      "Epoch 15/100\n",
      "2040/2040 [==============================] - 146s 71ms/step - loss: 10.3605 - val_loss: 11.1484\n",
      "Epoch 16/100\n",
      "2040/2040 [==============================] - 152s 74ms/step - loss: 10.3314 - val_loss: 11.1668\n",
      "Epoch 17/100\n",
      "2040/2040 [==============================] - 149s 73ms/step - loss: 10.3036 - val_loss: 11.0513\n",
      "INFO:tensorflow:Assets written to: /Users/romeo/Formation DataScientist/projet pynomaly/assets\n",
      "Epoch 18/100\n",
      "2040/2040 [==============================] - 144s 71ms/step - loss: 10.2854 - val_loss: 11.0487\n",
      "INFO:tensorflow:Assets written to: /Users/romeo/Formation DataScientist/projet pynomaly/assets\n",
      "Epoch 19/100\n",
      "2040/2040 [==============================] - 144s 70ms/step - loss: 10.2680 - val_loss: 11.1328\n",
      "Epoch 20/100\n",
      "2040/2040 [==============================] - 142s 70ms/step - loss: 10.2469 - val_loss: 10.9528\n",
      "INFO:tensorflow:Assets written to: /Users/romeo/Formation DataScientist/projet pynomaly/assets\n",
      "Epoch 21/100\n",
      "2040/2040 [==============================] - 146s 71ms/step - loss: 10.2288 - val_loss: 11.1067\n",
      "Epoch 22/100\n",
      "2040/2040 [==============================] - 145s 71ms/step - loss: 10.2164 - val_loss: 10.9736\n",
      "Epoch 23/100\n",
      "2040/2040 [==============================] - 147s 72ms/step - loss: 10.2066 - val_loss: 10.9767\n",
      "Epoch 24/100\n",
      "2040/2040 [==============================] - 146s 72ms/step - loss: 10.1845 - val_loss: 11.0013\n",
      "Epoch 25/100\n",
      "2040/2040 [==============================] - 150s 74ms/step - loss: 10.1747 - val_loss: 11.0830\n",
      "Epoch 26/100\n",
      "2040/2040 [==============================] - 146s 71ms/step - loss: 10.1619 - val_loss: 12.1684\n",
      "Epoch 27/100\n",
      "2040/2040 [==============================] - 154s 76ms/step - loss: 10.1591 - val_loss: 10.8465\n",
      "INFO:tensorflow:Assets written to: /Users/romeo/Formation DataScientist/projet pynomaly/assets\n",
      "Epoch 28/100\n",
      "2040/2040 [==============================] - 145s 71ms/step - loss: 10.1390 - val_loss: 10.8968\n",
      "Epoch 29/100\n",
      "2040/2040 [==============================] - 148s 73ms/step - loss: 10.1243 - val_loss: 11.0679\n",
      "Epoch 30/100\n",
      "2040/2040 [==============================] - 146s 72ms/step - loss: 10.1188 - val_loss: 10.8548\n",
      "Epoch 31/100\n",
      "2040/2040 [==============================] - 151s 74ms/step - loss: 10.1094 - val_loss: 12.0075\n",
      "Epoch 32/100\n",
      "2040/2040 [==============================] - 144s 71ms/step - loss: 10.1036 - val_loss: 10.8909\n",
      "Epoch 33/100\n",
      "2040/2040 [==============================] - 146s 71ms/step - loss: 10.0901 - val_loss: 11.0550\n",
      "Epoch 34/100\n",
      "2040/2040 [==============================] - 145s 71ms/step - loss: 10.1125 - val_loss: 10.7829\n",
      "INFO:tensorflow:Assets written to: /Users/romeo/Formation DataScientist/projet pynomaly/assets\n",
      "Epoch 35/100\n",
      "2040/2040 [==============================] - 152s 75ms/step - loss: 10.0743 - val_loss: 10.8949\n",
      "Epoch 36/100\n",
      "2040/2040 [==============================] - 146s 71ms/step - loss: 10.0661 - val_loss: 10.8083\n",
      "Epoch 37/100\n",
      "2040/2040 [==============================] - 143s 70ms/step - loss: 10.0639 - val_loss: 10.8781\n",
      "Epoch 38/100\n",
      "2040/2040 [==============================] - 140s 69ms/step - loss: 10.0562 - val_loss: 10.8727\n",
      "Epoch 39/100\n",
      "2040/2040 [==============================] - 144s 71ms/step - loss: 10.0498 - val_loss: 10.9513\n",
      "Epoch 40/100\n",
      "2040/2040 [==============================] - 147s 72ms/step - loss: 10.0438 - val_loss: 11.3426\n",
      "Epoch 41/100\n",
      "2040/2040 [==============================] - 141s 69ms/step - loss: 10.0426 - val_loss: 10.7551\n",
      "INFO:tensorflow:Assets written to: /Users/romeo/Formation DataScientist/projet pynomaly/assets\n",
      "Epoch 42/100\n",
      "2040/2040 [==============================] - 144s 71ms/step - loss: 10.0292 - val_loss: 10.8179\n",
      "Epoch 43/100\n",
      "2040/2040 [==============================] - 142s 70ms/step - loss: 10.0250 - val_loss: 10.8271\n",
      "Epoch 44/100\n",
      "2040/2040 [==============================] - 143s 70ms/step - loss: 10.0248 - val_loss: 10.7945\n",
      "Epoch 45/100\n",
      "2040/2040 [==============================] - 144s 70ms/step - loss: 10.0200 - val_loss: 12.4678\n",
      "Epoch 46/100\n",
      "2040/2040 [==============================] - 144s 71ms/step - loss: 10.0121 - val_loss: 10.9406\n",
      "Epoch 47/100\n",
      "2040/2040 [==============================] - 144s 70ms/step - loss: 10.0028 - val_loss: 10.8798\n",
      "Epoch 48/100\n",
      "2040/2040 [==============================] - 144s 71ms/step - loss: 10.0022 - val_loss: 10.7960\n",
      "Epoch 49/100\n",
      "2040/2040 [==============================] - 145s 71ms/step - loss: 9.9974 - val_loss: 10.8331\n",
      "Epoch 50/100\n",
      "2040/2040 [==============================] - 143s 70ms/step - loss: 9.9919 - val_loss: 11.0094\n",
      "Epoch 51/100\n",
      "2040/2040 [==============================] - 142s 70ms/step - loss: 9.9869 - val_loss: 10.8795\n",
      "Réalisé en 7596.618 secondes\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "# Callback pour arrêter l'entrainement et récupérer le meilleur modèle si la métrique ne diminue plus pendant 10 epochs\n",
    "early_stopping = callbacks.EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "filepath = cwd\n",
    "\n",
    "# Callback pour sauvegarder le meilleur modèle\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath = filepath, monitor = 'val_loss', save_best_only = True, \n",
    "                                       save_weights_only = False, mode = 'min', save_freq = 'epoch')\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# On entraine le modèle sur slider_train. \n",
    "model_dense.fit(slider_train_stream, slider_train_stream, batch_size = 512, epochs = 100, callbacks=[checkpoint, early_stopping], validation_split = 0.3)\n",
    "\n",
    "t1 = time() - t0\n",
    "print(\"Réalisé en {} secondes\".format(round(t1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x7fb96d2d8d60>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_dense_slider = tf.saved_model.load('/Users/romeo/Formation DataScientist/projet pynomaly')\n",
    "\n",
    "#model_dense_slider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On crée la dataset d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réalisé en 80.869 secondes\n"
     ]
    }
   ],
   "source": [
    "slider_test = df[(df.Dataset == 'test') & (df.Machine_Type == 'slider')]\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "slider_test_stream = dataset_stream(slider_test)\n",
    "\n",
    "t1 = time() - t0\n",
    "print(\"Réalisé en {} secondes\".format(round(t1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour déterminer le seuil à partir duquel on peut dire qu'une prise de son est anormale\n",
    "\n",
    "pred_slider_train = model_dense.predict(slider_train_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors(X_true, X_pred, length, nb_extract = 532): \n",
    "    \"\"\"\n",
    "    calcule les erreurs entre le jeu de départ et les prédictions du modèle\n",
    "    \"\"\"\n",
    "    vect_error = np.mean(np.square(X_true - X_pred), axis=1)\n",
    "    errors = np.zeros(length)\n",
    "    for k in range(length):\n",
    "        errors[k] = np.mean(vect_error[k*nb_extract : (k+1)*nb_extract])\n",
    "    return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne des erreurs : 10.263311256811678\n",
      "Ecart-type des erreurs : 1.030121709960901\n"
     ]
    }
   ],
   "source": [
    "error_slider_train = errors(slider_train_stream, pred_slider_train, len(slider_train))\n",
    "\n",
    "#print(error_slider)\n",
    "print('Moyenne des erreurs :', np.mean(error_slider_train))\n",
    "print('Ecart-type des erreurs :', np.std(error_slider_train))\n",
    "\n",
    "# Donc un seuil un peu plus grand que 11.3 est bien pour trouver les prises de sons anormales détectées par le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_slider_test = model_dense.predict(slider_test_stream)\n",
    "\n",
    "error_slider_test = errors(slider_test_stream, pred_slider_test, len(slider_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10679    0\n",
       "10680    1\n",
       "10681    1\n",
       "10682    0\n",
       "10683    0\n",
       "        ..\n",
       "11964    1\n",
       "11965    1\n",
       "11966    0\n",
       "11967    0\n",
       "11968    0\n",
       "Name: Status, Length: 1290, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = slider_test['Status'].replace(['normal', 'anomaly'], [0,1])\n",
    "\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classe prédite</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classe réelle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>314</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classe prédite    0    1\n",
       "Classe réelle           \n",
       "0               314   86\n",
       "1               112  778"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seuil = 11.4 # valeur à déterminer selon les erreurs \n",
    "\n",
    "y_pred = np.where(error_slider_test[:] > seuil, 1, 0)\n",
    "\n",
    "pd.crosstab(y_true, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75       400\n",
      "           1       0.90      0.86      0.88       890\n",
      "\n",
      "    accuracy                           0.84      1290\n",
      "   macro avg       0.81      0.83      0.82      1290\n",
      "weighted avg       0.84      0.84      0.84      1290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, seuils = roc_curve(y_true, error_slider, pos_label = 1)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, 'orange', label = 'Modèle dense (auc = %0.2f)' % roc_auc)\n",
    "plt.title('Courbe ROC')\n",
    "plt.xlabel('Taux faux positifs')\n",
    "plt.ylabel('Taux vrais positifs')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1.05)\n",
    "\n",
    "plt.plot(fpr, fpr, 'b--', label = 'Aléatoire (aux = 0.5)')\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.8295786516853934\n",
      "pAUC : 0.5806802084909164\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_true, y_pred)\n",
    "p_auc = roc_auc_score(y_true, y_pred, max_fpr=0.1)\n",
    "\n",
    "print(\"AUC : {}\".format(auc))\n",
    "print(\"pAUC : {}\".format(p_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinons notre analyse selon le Machine_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 6, 2, 4])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slider_train.Machine_ID.value_counts()\n",
    "slider_train.Machine_ID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premier Machine_ID : 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne des erreurs : 10.06757308332017\n",
      "Ecart-type des erreurs : 0.8538450127004871\n"
     ]
    }
   ],
   "source": [
    "error_slider_train_0 = error_slider_train[slider_train.Machine_ID == 0]\n",
    "\n",
    "print('Moyenne des erreurs :', np.mean(error_slider_train_0))\n",
    "print('Ecart-type des erreurs :', np.std(error_slider_train_0))\n",
    "\n",
    "seuil = 11.4 # valeur à déterminer selon les erreurs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88       100\n",
      "           1       0.95      0.99      0.97       356\n",
      "\n",
      "    accuracy                           0.95       456\n",
      "   macro avg       0.96      0.90      0.92       456\n",
      "weighted avg       0.95      0.95      0.95       456\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classe prédite</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classe réelle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classe prédite   0    1\n",
       "Classe réelle          \n",
       "0               80   20\n",
       "1                2  354"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_0 = y_true[slider_test.Machine_ID == 0]\n",
    "y_pred_0 = np.where(error_slider_test[slider_test.Machine_ID == 0][:] > seuil, 1, 0)\n",
    "\n",
    "print(classification_report(y_true_0, y_pred_0))\n",
    "pd.crosstab(y_true_0, y_pred_0, rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.897191011235955\n",
      "pAUC : 0.6045239503252513\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_true_0, y_pred_0)\n",
    "p_auc = roc_auc_score(y_true_0, y_pred_0, max_fpr=0.1)\n",
    "\n",
    "print(\"AUC : {}\".format(auc))\n",
    "print(\"pAUC : {}\".format(p_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deuxième Machine_ID : 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne des erreurs : 10.172492965291347\n",
      "Ecart-type des erreurs : 0.9994760888384666\n"
     ]
    }
   ],
   "source": [
    "error_slider_train_2 = error_slider_train[slider_train.Machine_ID == 2]\n",
    "\n",
    "print('Moyenne des erreurs :', np.mean(error_slider_train_2))\n",
    "print('Ecart-type des erreurs :', np.std(error_slider_train_2))\n",
    "\n",
    "seuil = 10.8 # valeur à déterminer selon les erreurs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.66      0.57       100\n",
      "           1       0.86      0.76      0.80       267\n",
      "\n",
      "    accuracy                           0.73       367\n",
      "   macro avg       0.68      0.71      0.69       367\n",
      "weighted avg       0.76      0.73      0.74       367\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classe prédite</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classe réelle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classe prédite   0    1\n",
       "Classe réelle          \n",
       "0               66   34\n",
       "1               65  202"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_2 = y_true[slider_test.Machine_ID == 2]\n",
    "y_pred_2 = np.where(error_slider_test[slider_test.Machine_ID == 2][:] > seuil, 1, 0)\n",
    "\n",
    "print(classification_report(y_true_2, y_pred_2))\n",
    "pd.crosstab(y_true_2, y_pred_2, rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.7082771535580523\n",
      "pAUC : 0.532241045442423\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_true_2, y_pred_2)\n",
    "p_auc = roc_auc_score(y_true_2, y_pred_2, max_fpr=0.1)\n",
    "\n",
    "print(\"AUC : {}\".format(auc))\n",
    "print(\"pAUC : {}\".format(p_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troisième Machine_ID : 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne des erreurs : 10.585692787462927\n",
      "Ecart-type des erreurs : 0.9945730578638943\n"
     ]
    }
   ],
   "source": [
    "error_slider_train_4 = error_slider_train[slider_train.Machine_ID == 4]\n",
    "\n",
    "print('Moyenne des erreurs :', np.mean(error_slider_train_4))\n",
    "print('Ecart-type des erreurs :', np.std(error_slider_train_4))\n",
    "\n",
    "seuil = 12 # valeur à déterminer selon les erreurs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92       100\n",
      "           1       0.93      0.99      0.96       178\n",
      "\n",
      "    accuracy                           0.95       278\n",
      "   macro avg       0.95      0.93      0.94       278\n",
      "weighted avg       0.95      0.95      0.95       278\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classe prédite</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classe réelle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classe prédite   0    1\n",
       "Classe réelle          \n",
       "0               87   13\n",
       "1                2  176"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_4 = y_true[slider_test.Machine_ID == 4]\n",
    "y_pred_4 = np.where(error_slider_test[slider_test.Machine_ID == 4][:] > seuil, 1, 0)\n",
    "\n",
    "print(classification_report(y_true_4, y_pred_4))\n",
    "pd.crosstab(y_true_4, y_pred_4, rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.92938202247191\n",
      "pAUC : 0.6738388754947005\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_true_4, y_pred_4)\n",
    "p_auc = roc_auc_score(y_true_4, y_pred_4, max_fpr=0.1)\n",
    "\n",
    "print(\"AUC : {}\".format(auc))\n",
    "print(\"pAUC : {}\".format(p_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quatrième Machine_ID : 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne des erreurs : 10.580069491440288\n",
      "Ecart-type des erreurs : 1.3055483512960364\n"
     ]
    }
   ],
   "source": [
    "error_slider_train_6 = error_slider_train[slider_train.Machine_ID == 6]\n",
    "\n",
    "print('Moyenne des erreurs :', np.mean(error_slider_train_6))\n",
    "print('Ecart-type des erreurs :', np.std(error_slider_train_6))\n",
    "\n",
    "seuil = 10.8 # valeur à déterminer selon les erreurs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.60      0.72       100\n",
      "           1       0.67      0.92      0.78        89\n",
      "\n",
      "    accuracy                           0.75       189\n",
      "   macro avg       0.78      0.76      0.75       189\n",
      "weighted avg       0.79      0.75      0.75       189\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classe prédite</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classe réelle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classe prédite   0   1\n",
       "Classe réelle         \n",
       "0               60  40\n",
       "1                7  82"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_6 = y_true[slider_test.Machine_ID == 6]\n",
    "y_pred_6 = np.where(error_slider_test[slider_test.Machine_ID == 6][:] > seuil, 1, 0)\n",
    "\n",
    "print(classification_report(y_true_6, y_pred_6))\n",
    "pd.crosstab(y_true_6, y_pred_6, rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.7606741573033708\n",
      "pAUC : 0.5342992312241277\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_true_6, y_pred_6)\n",
    "p_auc = roc_auc_score(y_true_6, y_pred_6, max_fpr=0.1)\n",
    "\n",
    "print(\"AUC : {}\".format(auc))\n",
    "print(\"pAUC : {}\".format(p_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
